{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-db7ac3dc86c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.1.0_1/libexec/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2315\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2317\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2318\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-108>\u001b[0m in \u001b[0;36mmatplotlib\u001b[0;34m(self, line)\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.1.0_1/libexec/lib/python3.8/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.1.0_1/libexec/lib/python3.8/site-packages/IPython/core/magics/pylab.py\u001b[0m in \u001b[0;36mmatplotlib\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Available matplotlib backends: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbackends_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_matplotlib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_matplotlib_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.1.0_1/libexec/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36menable_matplotlib\u001b[0;34m(self, gui)\u001b[0m\n\u001b[1;32m   3405\u001b[0m         \"\"\"\n\u001b[1;32m   3406\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpylabtools\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3407\u001b[0;31m         \u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_gui_and_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgui\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpylab_gui_select\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgui\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/2.1.0_1/libexec/lib/python3.8/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mfind_gui_and_backend\u001b[0;34m(gui, gui_select)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \"\"\"\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgui\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgui\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from pandas import Series\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from geopy.geocoders import Nominatim\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import gmplot\n",
    "\n",
    "#importing the dataset using pandas\n",
    "df = pd.read_csv(\"./911.csv\")\n",
    "\n",
    "#sample of original dataset\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate timeStamp data into 2 new columns\n",
    "df['date'] = df.timeStamp.str[0:11]\n",
    "df['time'] = df.timeStamp.str[-8:]\n",
    "\n",
    "#Get rid of dummy 'e' column and 'timeStamp' column\n",
    "del df['e']\n",
    "del df['timeStamp']\n",
    "#If time at end, then try to extract station number and impute\n",
    "del df['desc']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count number of values in each column\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finds total number of rows with missing values \n",
    "#Rows with more than one missing value only counted once\n",
    "df.isnull().any(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop rows with missing zipcode values\n",
    "df = df.dropna(subset=['zip'])\n",
    "\n",
    "#Convert float values for zipcodes to integer type\n",
    "df['zip'] = df['zip'].astype(int)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty = np.where(pd.isnull(df))\n",
    "geolocator = Nominatim()\n",
    "index = 0\n",
    "\n",
    "\n",
    "#Impute 24 missing township values\n",
    "for i in np.nditer(empty):\n",
    "    \n",
    "    #row of missing township cell\n",
    "    row = empty[0][index] \n",
    "    #column of missing township cell\n",
    "    column = empty[1][index]\n",
    "    \n",
    "    \n",
    "    temp_lat = repr(df.iloc[row,0])\n",
    "    temp_long = repr(df.iloc[row,1])\n",
    "    \n",
    "    \n",
    "    location = geolocator.reverse([temp_lat, temp_long], timeout = 60)\n",
    "    \n",
    "    if column == 4:\n",
    "        \n",
    "    \n",
    "        #extract township value from location dictionary\n",
    "        town = location.raw['address']['city'] \n",
    "    \n",
    "    \n",
    "        #remove 'Township' ending from name of town    \n",
    "        if town.endswith(\"Township\"):\n",
    "            town = town[0:-9]\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "                \n",
    "        #convert to uppercase to maintain township format in dataframe    \n",
    "        town = town.upper()\n",
    "    \n",
    "        #put imputed township name into corresponding missing cell of dataframe\n",
    "        df.iloc[row, column] = town\n",
    "    \n",
    "        print(df.iloc[row, column])\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        pass\n",
    "        \n",
    "        #Elected to comment out code to impute missing zipcodes because it would take too long (approx. 4-6 hrs.)\n",
    "        #zcode = location.raw['address']['postcode']\n",
    "        \n",
    "        #df.iloc[row, column] = zcode\n",
    "        \n",
    "        #print(df.iloc[row, column])\n",
    "    \n",
    "        \n",
    "    #increment index to get to next set of index values for empty township cell\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After imputing townships: No more missing values in the dataset\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour = df.time.str[0:2]\n",
    "hour2 = pd.to_numeric(hour)\n",
    "\n",
    "#If time of call is between 6PM and 6AM then it is classified as 'night', otherwise it is classified as 'day'\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    if(hour2.loc[i] >= 18 or hour2.loc[i] < 6):\n",
    "        hour.at[i] = 'night'\n",
    "    else:\n",
    "        hour.at[i] = 'day'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace military time with either 'night' or 'day'\n",
    "del df['time']\n",
    "\n",
    "df['time_of_day'] = hour   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change date format to weekdays format (ex. Monday, Tuesday ...)\n",
    "df['dates'] = pd.to_datetime(df['date'])\n",
    "df['weekday'] = df['dates'].dt.weekday_name\n",
    "\n",
    "del df['date']\n",
    "del df['dates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate first part of 911 call classification from rest of title\n",
    "df['class'], df['title2'] = df['title'].str.split(':', 1).str\n",
    "del df['title']\n",
    "del df['title2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#end of general preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique zipcodes in the dataset\n",
    "df.zip.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the number of unique zipcodes\n",
    "s = Series(df.zip)\n",
    "zip_unique = s.unique().size\n",
    "print(zip_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique townships in the dataset\n",
    "df.twp.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the number of unique townships\n",
    "s2 = Series(df.twp)\n",
    "twp_unique = s2.unique().size\n",
    "print(twp_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the number of unique address locations\n",
    "s4 = Series(df.addr)\n",
    "s4.unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find number of unique latitude values\n",
    "sLat = Series(df.lat)\n",
    "sLat.unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find number of unique longitude values\n",
    "sLong = Series(df.lng)\n",
    "sLong.unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find max, min latitudes and longitudes\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used code from https://www.kaggle.com/vishnoiprem/d/mchirico/montcoalert/911-calls-visualization\n",
    "# modified some code and added to the visulization\n",
    "DATA = np.zeros((df.shape[0],7),dtype='O')\n",
    "DATA[:,0] = df['lng'].values\n",
    "DATA[:,1] = df['lat'].values\n",
    "DATA[:,2] = df['zip'].values\n",
    "DATA[:,3] = df['weekday'].values\n",
    "DATA[:,4] = df['time_of_day'].values\n",
    "DATA[:,5] = df['addr'].values\n",
    "DATA[:,6] = df['class'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeOfCall = np.zeros(DATA.shape[0],dtype='O')\n",
    "for i in range(typeOfCall.size):\n",
    "    typeOfCall[i] = DATA[i][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_type = np.array([\"Ems\", \"Fire\", \"Traffic\"])\n",
    "sns.plt.figure(figsize=(12,4))\n",
    "sns.plt.xlabel(\"Type of Incident\")\n",
    "sns.plt.title(\"All Situations By Time\")\n",
    "sns.countplot(typeOfCall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Additional Preprocessing for Bagging and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change string data to label encoded integers for Bagging & RandomForest Classifier\n",
    "le_dow = preprocessing.LabelEncoder()\n",
    "le_tod = preprocessing.LabelEncoder()\n",
    "le_addr = preprocessing.LabelEncoder()\n",
    "le_twp = preprocessing.LabelEncoder()\n",
    "le_class = preprocessing.LabelEncoder()\n",
    "\n",
    "le_dow = le_dow.fit_transform(df['weekday'])\n",
    "le_tod = le_tod.fit_transform(df['time_of_day'])\n",
    "le_addr = le_addr.fit_transform(df['addr'])\n",
    "le_twp = le_twp.fit_transform(df['twp'])\n",
    "le_class = le_class.fit_transform(df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create copy of dataframe\n",
    "df2 = df.copy()\n",
    "\n",
    "#Delete old columns with string values and replace with new label encoded columns\n",
    "del df2['weekday']\n",
    "del df2['time_of_day']\n",
    "del df2['addr']\n",
    "del df2['twp']\n",
    "del df2['class']\n",
    "\n",
    "\n",
    "df2['weekday'] = le_dow\n",
    "df2['time_of_day'] = le_tod\n",
    "df2['addr'] = le_addr\n",
    "df2['twp'] = le_twp\n",
    "df2['class'] = le_class\n",
    "\n",
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset for building Bagging classifier\n",
    "x = df2[['lat', 'lng', 'zip', 'twp', 'addr', 'time_of_day', 'weekday']].copy()\n",
    "y = df2[['class']].copy()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view input attributes for Bagging and Random Forest classifiers\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view output values for Bagging and Random Forest\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = BaggingClassifier(base_estimator=None, max_features=7, n_estimators=100, n_jobs=-1, random_state=0)\n",
    "bag.fit(x_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy on training set: {:.3f}\".format(bag.score(x_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(bag.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag1 = BaggingClassifier(base_estimator=KNeighborsClassifier(n_jobs=-1, p=1, n_neighbors=10), max_features=7, n_estimators=100, n_jobs=-1, random_state=0)\n",
    "bag1.fit(x_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy on training set: {:.3f}\".format(bag1.score(x_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(bag1.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manual 80/20 Train/Test split since data is timeseries data (newer data should be test data)\n",
    "x_train2 = x[:124766]\n",
    "x_test2 = x[124766:]\n",
    "\n",
    "y_train2 = y[:124766]\n",
    "y_test2 = y[124766:]\n",
    "\n",
    "forest2 = RandomForestClassifier(n_estimators=100, criterion='entropy', max_features=5, max_depth=25, \n",
    "                                 min_impurity_split=0.9, n_jobs=-1, random_state=0)\n",
    "\n",
    "forest2.fit(x_train2, y_train2.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy on training set: {:.3f}\".format(forest2.score(x_train2, y_train2)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(forest2.score(x_test2, y_test2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important = forest2.feature_importances_\n",
    "print ('Feature importance:\\n')\n",
    "\n",
    "#Print importance value for each feature\n",
    "for i in range(7):\n",
    "    print(df2.columns.values[i],': ',important[i], '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 7\n",
    "names = []\n",
    "\n",
    "for i in range(n_features):\n",
    "    names.append(df2.columns.values[i])\n",
    "\n",
    "#Plot importance of attributes for Random Forest Classifier\n",
    "plt.barh(range(n_features), forest2.feature_importances_, align='center')\n",
    "plt.yticks(np.arange(n_features), names)\n",
    "plt.xlabel(\"911 Dataset Feature importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVC (Support Vector Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a copy of data set to start transforming attributes into float \n",
    "df3= df.copy()\n",
    "\n",
    "df3.head()\n",
    "\n",
    "#uncomment the next two lines to encode the addresses for input in classification\n",
    "le_addr = preprocessing.LabelEncoder()\n",
    "le_addr = le_addr.fit_transform(df3['addr'])\n",
    "\n",
    "\n",
    "#delete addrs attribute\n",
    "#del df3['addr']\n",
    "\n",
    "#uncomment next line and comment out previous line if keeping addresses is desired\n",
    "df3['addr'] = le_addr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformed dataframe to dictionary for additional preprocessing\n",
    "comb = [df3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in comb:\n",
    "    dataset['time_of_day'] = dataset['time_of_day'].map( {'day': 1,'night': 2} ).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in comb:\n",
    "    dataset['class'] = dataset['class'].map( {'Traffic': 10,'EMS': 20, 'Fire': 30} ).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in comb:\n",
    "     dataset['weekday'] = dataset['weekday'].map( {'Monday': 11,'Tuesday': 22,'Wednesday': 33,'Thursday': 44,'Friday': 55,'Saturday': 66, 'Sunday': 77} ).astype(float) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using unique float values for each mapping\n",
    "for dataset in comb:\n",
    "    dataset['twp'] = dataset['twp'].map({'NEW HANOVER' :101, 'HATFIELD TOWNSHIP': 111, 'NORRISTOWN': 12, 'LANSDALE': 13,\n",
    "       'HORSHAM': 14, 'SKIPPACK': 15, 'LOWER SALFORD': 16, 'PLYMOUTH': 17,\n",
    "       'UPPER MORELAND': 18, 'CHELTENHAM': 19, 'MONTGOMERY': 202, 'WHITEMARSH': 21,\n",
    "       'UPPER GWYNEDD': 222, 'LOWER PROVIDENCE': 23, 'WHITPAIN': 24, 'DELAWARE COUNTY': 25,\n",
    "       'FRANCONIA': 76, 'WEST CONSHOHOCKEN': 777, 'UPPER MERION': 78, 'LIMERICK': 79,\n",
    "       'DOUGLASS': 26, 'LOWER MERION': 27, 'POTTSTOWN': 28, 'BRIDGEPORT': 29, 'TOWAMENCIN': 303,\n",
    "       'AMBLER': 31, 'LOWER POTTSGROVE': 32, 'CHESTER COUNTY': 333, 'UPPER HANOVER': 34,\n",
    "       'SPRINGFIELD': 35, 'ROCKLEDGE': 36, 'ABINGTON': 37, 'WEST NORRITON': 38,\n",
    "       'ROYERSFORD': 39, 'UPPER DUBLIN': 40, 'UPPER SALFORD': 41, 'CONSHOHOCKEN': 42,\n",
    "       'PENNSBURG': 43, 'TELFORD': 444, 'EAST NORRITON': 45, 'UPPER FREDERICK': 46,\n",
    "       'UPPER PROVIDENCE': 47, 'SALFORD': 48, 'LEHIGH COUNTY': 49, 'MARLBOROUGH': 50,\n",
    "       'BRYN ATHYN': 51, 'LOWER MORELAND': 52, 'HATBORO': 53, 'LOWER GWYNEDD': 54,\n",
    "       'WORCESTER': 555, 'COLLEGEVILLE': 56, 'SCHWENKSVILLE': 57, 'SOUDERTON': 58,\n",
    "       'PERKIOMEN': 59, 'LOWER FREDERICK': 60, 'BUCKS COUNTY': 61, 'RED HILL': 62,\n",
    "       'WEST POTTSGROVE': 63, 'UPPER POTTSGROVE': 64, 'EAST GREENVILLE': 65,\n",
    "       'NORTH WALES': 666,'JENKINTOWN': 67,'TRAPPE': 68, 'NARBERTH': 69, 'BERKS COUNTY': 70,\n",
    "       'GREEN LANE': 71, 'WARRINGTON': 72, 'PHILA COUNTY': 73, 'HATFIELD': 74,\n",
    "       'HATFIELD BORO': 75}).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into training and testing sets\n",
    "#uncoment this next line and comment out the following line to keep address feature\n",
    "x3 = df3[['lat', 'lng', 'zip', 'addr', 'twp', 'time_of_day', 'weekday']].copy()\n",
    "\n",
    "#x3 = df3[['lat', 'lng', 'zip', 'twp', 'time_of_day', 'weekday']].copy()\n",
    "y3 = df3[['class']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train3, x_test3, y_train3, y_test3 = train_test_split(x3, y3, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Linear SVC model\n",
    "model = OneVsRestClassifier(LinearSVC(penalty='l2', loss='squared_hinge', dual=True, tol=0.0001, C=1.0, multi_class='ovr', fit_intercept=True, intercept_scaling=1, \n",
    "                                      class_weight=None, verbose=0, random_state=None, max_iter=100))\n",
    "\n",
    "model.fit(x_train3,y_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy on training set: {:.3f}\".format(model.score(x_train3, y_train3)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(model.score(x_test3, y_test3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment next two blocks of code to use kernel SVC, runtime is approximately 1-1.5 hours\n",
    "#from sklearn import svm\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(x_train3,y_train3.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy on training set: {:.3f}\".format(clf.score(x_train3, y_train3)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(clf.score(x_test3, y_test3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arrays for all latitudes and longitudes \n",
    "lats = []\n",
    "longs = []\n",
    "\n",
    "#Arrays for latitude and longitude of each different 911 call type\n",
    "ems_lat = []\n",
    "ems_long = []\n",
    "fire_lat = []\n",
    "fire_long = []\n",
    "traffic_lat = []\n",
    "traffic_long = []\n",
    "\n",
    "\n",
    "#Put latitute and longitude of 911 calls into arrays for maps\n",
    "for i in range(155957):\n",
    "    lats.append(df2.iloc[i, 0])\n",
    "    longs.append(df2.iloc[i, 1])\n",
    "    \n",
    "    #911 call for EMS\n",
    "    if df2.iloc[i, 7] == 0:\n",
    "        ems_lat.append(df2.iloc[i, 0])\n",
    "        ems_long.append(df2.iloc[i, 1])\n",
    "    \n",
    "    #911 call for Fire\n",
    "    elif df2.iloc[i, 7] == 1:\n",
    "        fire_lat.append(df2.iloc[i, 0])\n",
    "        fire_long.append(df2.iloc[i, 1])\n",
    "    \n",
    "    #911 call for Traffic\n",
    "    else:\n",
    "        traffic_lat.append(df2.iloc[i, 0])\n",
    "        traffic_long.append(df2.iloc[i, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Latitudes and Longitudes for plotting boundaries of Montgomery County Pennsylvania\n",
    "lat_bound = (40.241979, 40.447123, 40.138185, 40.069056, 40.063658, 40.046278, 40.084713, \n",
    "40.073154, 40.092990, 40.054093, 40.011573, 39.977010, 40.019547, 40.015951, 40.072212, \n",
    "40.060884, 40.097123, 40.090095, 40.094000, 40.087753, 40.115236, 40.126164, 40.129910,\n",
    "40.147977, 40.194150, 40.223927, 40.236395, 40.241979)\n",
    "\n",
    "long_bound = (-75.696874, -75.529820, -75.015042, -75.096642, -75.087832, -75.110155,\n",
    "-75.176633, -75.188473, -75.223789, -75.264413, -75.206578, -75.276598, -75.311506, \n",
    "-75.320488, -75.367236, -75.392806, -75.420365, -75.437921, -75.440779, -75.456498, \n",
    "-75.471208, -75.463654, -75.500604, -75.524058, -75.569582, -75.608164, -75.687167, -75.696874)                    \n",
    "\n",
    "\n",
    "#Create map centered at lat, long, amount of zoom\n",
    "gmap = gmplot.GoogleMapPlotter(40.194126, -75.362524, 8.5)\n",
    "\n",
    "#Plot outline of Montgomery County\n",
    "gmap.plot(lat_bound, long_bound, 'cornflowerblue', edge_width=5)\n",
    "\n",
    "#Plot 911 call location in heatmap form\n",
    "gmap.heatmap(lats, longs)\n",
    "\n",
    "#Save html file of Google map\n",
    "gmap.draw(\"Montgomery_County_Heatmap.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create map centered at lat, long, amount of zoom\n",
    "gmap2 = gmplot.GoogleMapPlotter(40.194126, -75.362524, 10)\n",
    "\n",
    "#Plot outline of Montgomery County\n",
    "gmap2.plot(lat_bound, long_bound, 'cornflowerblue', edge_width=5)\n",
    "\n",
    "#Plot first 10,000 EMS, Fire, and Traffic 911 call locations onto map (30,000 call locations total)\n",
    "#EMS = green\n",
    "gmap2.scatter(ems_lat[0:10000],ems_long[0:10000] , 'g', 5, marker=False)\n",
    "#Fire = red\n",
    "gmap2.scatter(fire_lat[0:10000],fire_long[0:10000] , 'r', 5, marker=False)\n",
    "#Traffic = yellow\n",
    "gmap2.scatter(traffic_lat[0:10000],traffic_long[0:10000] , 'y', 5, marker=False)\n",
    "\n",
    "\n",
    "#Save html file of Google map\n",
    "gmap2.draw(\"911_Call_Locations.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
